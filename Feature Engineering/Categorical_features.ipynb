{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Categorical features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhfKlPxSxPctJp2xNRLWEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JP109/ML-Basics/blob/main/Feature%20Engineering/Categorical_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePe8Tzf-pAtE"
      },
      "source": [
        "### **Encoding categorical features**\n",
        "\n",
        "You might be tempted to encode this data with a straightforward numerical mapping:{'Queen Anne': 1, 'Fremont': 2, 'Wallingford': 3};\n",
        "\n",
        "This is not a useful approach in Scikit-Learn: the package's models make the fundamental assumption that numerical features reflect algebraic quantities. Thus such a mapping would imply, for example, that Queen Anne < Fremont < Wallingford, or even that Wallingford - Queen Anne = Fremont, which (niche demographic jokes aside) does not make much sense.\n",
        "\n",
        "Better methods for vectorizing categorical features:\n",
        "1. **One hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7gpVfejo25f"
      },
      "source": [
        "data = [\n",
        "    {'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},\n",
        "    {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},\n",
        "    {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},\n",
        "    {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}\n",
        "]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbZpUp-NrRxv",
        "outputId": "1a8fe988-7048-4d55-fce4-0dfa3a4b49e4"
      },
      "source": [
        "# When data is in the form of a list of dictionaries:\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "vec = DictVectorizer(sparse=False, dtype=int)\n",
        "vec.fit_transform(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     0,      1,      0, 850000,      4],\n",
              "       [     1,      0,      0, 700000,      3],\n",
              "       [     0,      0,      1, 650000,      3],\n",
              "       [     1,      0,      0, 600000,      2]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f2BHx-9rcH7",
        "outputId": "f3d2b80a-280a-4bde-90fc-f96605f1b2f8"
      },
      "source": [
        "# Get meaning of each column:\n",
        "vec.get_feature_names()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neighborhood=Fremont',\n",
              " 'neighborhood=Queen Anne',\n",
              " 'neighborhood=Wallingford',\n",
              " 'price',\n",
              " 'rooms']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QtXdTN2r6bz"
      },
      "source": [
        "If your category has many possible values, this can greatly increase the size of your dataset. However, because the encoded data contains mostly zeros, a sparse output can be a very efficient solution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCivhzXFr0V-",
        "outputId": "ac9ade0a-7617-437a-ac8d-eab49615df4f"
      },
      "source": [
        "vec = DictVectorizer(sparse=True, dtype=int)\n",
        "vec.fit_transform(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x5 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 12 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwtlwTdGr_aG"
      },
      "source": [
        "Many (though not yet all) of the Scikit-Learn estimators accept such sparse inputs when fitting and evaluating models. sklearn.preprocessing.OneHotEncoder and sklearn.feature_extraction.FeatureHasher are two additional tools that Scikit-Learn includes to support this type of encoding."
      ]
    }
  ]
}